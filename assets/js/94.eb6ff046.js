(window.webpackJsonp=window.webpackJsonp||[]).push([[94],{652:function(e,a,i){"use strict";i.r(a);var t=i(35),n=Object(t.a)({},(function(){var e=this,a=e.$createElement,i=e._self._c||a;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h1",{attrs:{id:"hifi4g-high-fidelity-human-performance-rendering-via-compact-gaussian-splatting"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#hifi4g-high-fidelity-human-performance-rendering-via-compact-gaussian-splatting"}},[e._v("#")]),e._v(" HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian Splatting")]),e._v(" "),i("p",[e._v("3D Gaussian + non-rigid tracking")]),e._v(" "),i("ul",[i("li",[i("p",[i("strong",[e._v("Dynamic scene modeling")])]),e._v(" "),i("p",[e._v("dual-graph mechanism to obtain motion priors")]),e._v(" "),i("ul",[i("li",[e._v("a coarse deformation graph for effective initialization")]),e._v(" "),i("li",[e._v("a fine-grained Gaussian graph to enforce subsequent constraints")])]),e._v(" "),i("p",[e._v("spatial-temporal regularizers to effectively balance the non-rigid prior and Gaussian updating")])]),e._v(" "),i("li",[i("p",[i("strong",[e._v("Compression")]),e._v(" scheme with residual compensation, ~25x compression rate, with less than 2MB of storage per frame")])])]),e._v(" "),i("h2",{attrs:{id:"related-work"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#related-work"}},[e._v("#")]),e._v(" Related Work")]),e._v(" "),i("p",[i("strong",[e._v("Dynamic")])]),e._v(" "),i("ul",[i("li",[e._v("NeRF-family")]),e._v(" "),i("li",[e._v("a few 3DGS recent work\n"),i("ul",[i("li",[e._v("Dynamic GS")]),e._v(" "),i("li",[e._v("[69, 72] implicit deformation network")])])])]),e._v(" "),i("p",[i("strong",[e._v("Compression")])]),e._v(" "),i("ul",[i("li",[e._v('"A series of works are proposed for early point cloud compression with Octree [53, 63], Wavelet [41]. These are formalized into MPEG-PCC [54] standards by the Moving Picture Experts Group (MPEG), which are categorized into video-based (VPCC) and geometry-based (GPCC)."')]),e._v(" "),i("li",[e._v("learning-based methods, e.g., tensor/scene decomposition, tri-planes and multi-planes")])]),e._v(" "),i("h2",{attrs:{id:"methods"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#methods"}},[e._v("#")]),e._v(" Methods")]),e._v(" "),i("p",[i("strong",[e._v("Coarse deformation graph")])]),e._v(" "),i("ul",[i("li",[e._v("Non-rigid tracking\n"),i("ul",[i("li",[e._v("DynamicFusion, DoubleFusion")])])]),e._v(" "),i("li",[e._v("Key-frame segementing (segmenting the data sequence into multiple key volumes)\n"),i("ul",[i("li",[e._v("Fusion4d: Real-time performance capture of challenging scenes ("),i("a",{attrs:{href:"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/a114-dou.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("link"),i("OutboundLink")],1),e._v(")")]),e._v(" "),i("li",[e._v("Flyfusion: Realtime dynamic scene reconstruction using a flying depth camera (Lan Xu, Yebin Liu)")])])])]),e._v(" "),i("p",[i("strong",[e._v("Fine-grained gaussian graph")])]),e._v(" "),i("ul",[i("li",[e._v("initialize Gaussians from the NeuS2 mesh")]),e._v(" "),i("li",[e._v("increase the sampling density in the hand and face regions to significantly improve visual quality")]),e._v(" "),i("li",[i("strong",[e._v("key-volume update strategy")]),e._v(" "),i("ul",[i("li",[e._v("prune incorrect Gaussians from the previous keyframe and densify new ones at the current keyframe(?)")]),e._v(" "),i("li",[e._v("then restrict the number of Gaussians within the current segement")])])]),e._v(" "),i("li",[e._v("Afterward, we establish a fine-grained Gaussian graph(?)")])]),e._v(" "),i("p",[i("strong",[e._v("4D Gaussians Optimization")])]),e._v(" "),i("ul",[i("li",[e._v("not use the Gaussians' densification and pruning within the segment")]),e._v(" "),i("li",[e._v("categorize attributes into two groups\n"),i("ul",[i("li",[e._v("appearance-aware parameters: scaling, opacity, SH")]),e._v(" "),i("li",[e._v("motion-aware parameters: position, rotation")])])]),e._v(" "),i("li",[e._v("problem: temporal jitter\n"),i("ul",[i("li",[e._v("previous work: decoupling the deformation field from canonical 3D Gaussians (a fixed set of Gaussians across dynamic sequences)\n"),i("ul",[i("li",[e._v("-> substantially diminishes view-dependent effects and sacrifices rendering quality")])])]),e._v(" "),i("li",[e._v("this paper: introduce temporal and smooth regularization to delicately balance the dual graph prior and the updating of Gaussian attributes\n"),i("ul",[i("li",[e._v("temporal regularization: ensuring similar "),i("em",[e._v("appearance-aware parameters")]),e._v(" between adjacent frames")]),e._v(" "),i("li",[e._v("smooth regularization: "),i("em",[e._v("motion-aware parameters")]),e._v(", locally as-rigid-as-possible deformations")]),e._v(" "),i("li",[e._v("adaptive weight (on Gaussians) taking into account the displacement of positions between adjacent frames")])])])])])]),e._v(" "),i("p",[i("strong",[e._v("Compression")])]),e._v(" "),i("ul",[i("li",[i("strong",[e._v("residual compensation")]),e._v(" "),i("ul",[i("li",[e._v("retain keyframe attributes and calculate residuals for non-keyframes")]),e._v(" "),i("li",[e._v("for appearance attributes: just use residual")]),e._v(" "),i("li",[e._v("for motion attributes: related to embedded deformation")])])]),e._v(" "),i("li",[i("strong",[e._v("quantization")]),e._v(" attribute values")]),e._v(" "),i("li",[i("strong",[e._v("entropy encoding")]),e._v(" Ranged Arithmetic Numerical System (RANS)")])]),e._v(" "),i("h2",{attrs:{id:"implementation-details"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#implementation-details"}},[e._v("#")]),e._v(" Implementation Details")]),e._v(" "),i("ul",[i("li",[e._v("BackgroundMattingV2 (prior to RVM)")]),e._v(" "),i("li",[e._v("body, hands, face sampling ratio ~ 8:1:1 (~OpenPose)")]),e._v(" "),i("li",[e._v("quantize appearance attributes and fix -> fine-tune motion attributes -> quantize motion\n"),i("ul",[i("li",[e._v("different quantization levels depending on key/non-key frames, appearance/motion parameters")])])])]),e._v(" "),i("h2",{attrs:{id:"experiments"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#experiments"}},[e._v("#")]),e._v(" Experiments")]),e._v(" "),i("p",[e._v("81 Z-CAM, 4k 30fps")])])}),[],!1,null,null,null);a.default=n.exports}}]);