---
sidebar: auto
---

# ç¥ç»ç½‘ç»œå¯è§£é‡Šæ€§ç»¼è¿°

<link rel="stylesheet" href="/notes/katex.min.css">

## å‰è¨€

ä» 2017 å¹´åº•å°±å¼€å§‹è°ƒç ”ç¥ç»ç½‘ç»œå¯è§£é‡Šæ€§æ–¹é¢çš„ç ”ç©¶äº†ï¼Œä½†æ˜¯ç”±äºå„ç§åŸå› ä¸€ç›´æ‹–æ‹–æ‹–åˆ°æœ€è¿‘æ‰æ­£å¼æ”¾åˆ°ç½‘ä¸Šã€‚å°¤å…¶ä»Šå¹´çœ‹åˆ°è®¸å¤šæ–°çš„å·¥ä½œéƒ½é€æ¸å¡«è¡¥äº†ä»æˆ‘ä»¬çš„è®ºæ–‡å½’çº³ä¸­èƒ½æ˜æ˜¾å‘ç°çš„ç©ºç™½éƒ¨åˆ†ï¼Œæ„Ÿè§‰æˆ‘ä»¬çš„æ€è€ƒè¿˜æ˜¯æœ‰ä¸€äº›åˆ†äº«ä»·å€¼çš„ï¼Œå°±å½“æŠ›ç –å¼•ç‰äº†ï¼ˆä¹Ÿå¯ä»¥é˜…è¯» [arXiv ç‰ˆæœ¬](https://arxiv.org/abs/2012.14261)æˆ–[çŸ¥ä¹æ–‡ç« ](https://zhuanlan.zhihu.com/p/341153242)ï¼‰

å¤šè¯´ä¸€ç‚¹é¢˜å¤–è¯ï¼Œå› ä¸ºå¯è§£é‡Šæ€§çš„ç ”ç©¶æ¯”è¾ƒæ‚ä¹±ï¼Œåˆšå¼€å§‹è°ƒç ”çš„æ—¶å€™åªå¥½ä½¿ç”¨æš´åŠ›æœç´¢æ¥å¯»æ‰¾ç›¸å…³çš„æ–‡ç« ï¼Œç›´è§‚åœ°ä½“ä¼šåˆ°äº†è¿™ä¸€æ³¢æ·±åº¦å­¦ä¹ çƒ­æ½®è®©å¤šå°‘ä¼šè®®çš„è®ºæ–‡æ•°é‡å¤§å¢ğŸ˜‚

<figure>
  <img src="./imgs/interpretability/papers.png" alt="" class="border">
</figure>

## What. ä»€ä¹ˆæ˜¯å¯è§£é‡Šæ€§

<!-- åŒºåˆ†å­¦ä¹ ç†è®º -->

ä»ä¸»æµçš„å­¦æœ¯ç ”ç©¶æ¥è¯´ï¼Œ==å¯è§£é‡Šæ€§== **(interpretability)** è¿™ä¸ªè¯ä¸»è¦æ˜¯æŒ‡è§£é‡Š **å…·ä½“çš„ / å·²ç»è®­ç»ƒå¥½çš„ç½‘ç»œ**ã€‚ä½†æ˜¯åœ¨æ—¥å¸¸è¯´æ³•ä¸­ï¼Œå¯¹æ·±åº¦å­¦ä¹ ç†è®ºçš„ç ”ç©¶ä¹Ÿå¸¸è¢«ç§°ä¸º **æ·±åº¦å­¦ä¹ çš„å¯è§£é‡Šæ€§**ã€‚ä¸¤è€…çš„å·®åˆ«åœ¨äº**è§£é‡Šçš„å¯¹è±¡**ï¼Œå…¶ä¸­åè€…æƒ³è§£é‡Šçš„æ˜¯**æ·±åº¦å­¦ä¹ è¿™å¥—æ–¹æ³•**ï¼ˆä¸ºä»€ä¹ˆè¿™ä¹ˆå¥½ç”¨ï¼‰ã€‚æœ¬æ–‡æˆ‘ä»¬åªå…³æ³¨å‰è€…â€”â€”å…·ä½“çš„ç½‘ç»œçš„å¯è§£é‡Šæ€§ï¼Œä¸è¿‡åœ¨æ–‡ç« çš„æœ€åä¹Ÿé¡ºä¾¿ä»‹ç»ä¸€äº›ä¸åè€…ç›¸å…³çš„å†…å®¹ã€‚

<figure>
  <img src="./imgs/interpretability/disambiguation.gif" alt="" class="border">
</figure>

ä¸€ä¸ªå…·ä½“çš„ç¥ç»ç½‘ç»œæ— éæ˜¯ä¸€ä¸ªä»è¾“å…¥ $x$ åˆ°è¾“å‡º $y$ çš„éçº¿æ€§æ˜ å°„ï¼Œå¯è§£é‡Šæ€§å°±æ˜¯æƒ³ç†è§£è¿™ä¸ªæ˜ å°„èƒŒåçš„ã€Œæ€è·¯ / é€»è¾‘ / rationaleã€ï¼Œè€Œä¸æ˜¯ä»…ä»…çŸ¥é“è¯¥ç»“æœæ˜¯æ€ä¹ˆç»è¿‡ä¸€å †æ„ä¹‰ä¸æ˜çš„æ•°å€¼ï¼ˆæƒå€¼ï¼‰è®¡ç®—å‡ºæ¥çš„ã€‚æˆ‘ä»¬é‡‡ç”¨ä»¥å¾€è®ºæ–‡ä¸­æåˆ°çš„ä¸€ç§é‡Šä¹‰ï¼Œ

> **Interpretability** is the ability to provide *explanations*<sup>1</sup> in *understandable terms*<sup>2</sup> to a human.
> <sub>â¸º F. Doshi-Velez and B. Kim, â€œTowards A Rigorous Science of Interpretable Machine Learningâ€, <em>arXiv</em>, 2017.</sub>

å…¶ä¸­æˆ‘ä»¬**é¢å¤–å¼ºè°ƒä¸¤ç‚¹**ï¼š

1. **è§£é‡Š explanations**ï¼Œè¯´åˆ°åº•æ˜¯éœ€è¦ç”¨æŸç§ã€Œè¯­è¨€ã€æ¥æè¿°çš„ï¼ˆè‡ªç„¶è¯­è¨€ï¼Œé€»è¾‘è¯­å¥ç­‰ç­‰ï¼‰ã€‚ç†æƒ³æƒ…å†µä¸‹å½“ç„¶ä½¿ç”¨é€»è¾‘è§„åˆ™çš„å½¢å¼æœ€æ¸…æ™°ï¼Œä½†æ˜¯å®è·µä¸Šäººä»¬å¾€å¾€ä¸å¼ºæ±‚ã€Œå®Œæ•´çš„è§£é‡Šã€ï¼Œåªè¦èƒ½æä¾›ä¸€å®šç¨‹åº¦çš„ä¿¡æ¯ï¼Œå‰©ä¸‹çš„å¯ä»¥é è‡ªå·±è„‘è¡¥ï¼ˆå› æ­¤äº§ç”Ÿäº†è®¸å¤šä¸åŒç±»å‹çš„è§£é‡Šï¼Œæ¯”å¦‚ saliency mapsï¼‰

2. **å¯ç†è§£çš„æœ¯è¯­ understandable terms**ï¼Œæ˜¯æ„æˆè§£é‡Šçš„åŸºæœ¬å•å…ƒã€‚ä¸åŒé¢†åŸŸçš„æ¨¡å‹çš„è§£é‡Šéœ€è¦å»ºç«‹åœ¨ä¸åŒçš„é¢†åŸŸæœ¯è¯­ä¹‹ä¸Šï¼Œæ¯”å¦‚
   <p style="text-align: center; margin-top: -0.5em;"><img src="./imgs/interpretability/terms.png" alt="" width="500" class="border"></p>

ç®€å•æ¥è¯´ï¼Œæˆ‘ä»¬å°¤å…¶å…³æ³¨å¯è§£é‡Šæ€§ä¸­ **è§£é‡Š (explanation)** çš„è§’è‰²ã€‚è™½ç„¶è§£é‡Šçš„å½¢å¼æœ‰å¾ˆå¤šç§ï¼Œä½†å®ƒä»¬ç»ˆå½’å¯ä»¥æ˜¾å¼æˆ–éšå¼åœ°è¡¨è¾¾æˆé€»è¾‘è§„åˆ™çš„å½¢å¼ï¼ˆè¿™ä¼šæˆä¸ºåé¢ä¸€ä¸ªé‡è¦çš„è®ºæ–‡åˆ†ç±»ç»´åº¦ï¼‰

## Why. ä¸ºä»€ä¹ˆéœ€è¦å¯è§£é‡Šæ€§

ä¸ºä»€ä¹ˆéœ€è¦å¯è§£é‡Šæ€§è¿™ä¸ªé—®é¢˜ä¹Ÿæœ‰è®¸å¤šä¸åŒçš„è¯´æ³•ã€‚ä¸€ä¸ªæœ€å¸¸è§çš„è®¨è®ºå°±æ˜¯ **ä¿¡ä»» (trust)** é—®é¢˜ï¼Œä¸è¿‡ä¿¡ä»»æœ¬èº«è¿˜å—å¾ˆå¤šä¸»è§‚å› ç´ å½±å“ï¼Œéš¾ä»¥è®¨è®ºå‡ºä»€ä¹ˆç»“æœã€‚é€šè¿‡å¯¹ç›¸å…³æ–‡çŒ®çš„æ€»ç»“ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå„ç§ç†ç”±æ‹†è§£å½’çº³ä¸º 3 ç±»ï¼š

- **é«˜å¯é æ€§è¦æ±‚**
  ç¥ç»ç½‘ç»œåœ¨å®é™…ä½¿ç”¨ä¸­ç»å¸¸è¢«å‘ç°æœ‰ä¸€äº›æ„æƒ³ä¸åˆ°çš„é”™è¯¯ï¼ˆæ›´ä¸ç”¨è¯´å¯¹æŠ—æ”»å‡»ï¼‰ï¼Œè¿™å¯¹ä¸€äº›è¦æ±‚é«˜å¯é æ€§çš„ç³»ç»Ÿæ¥è¯´å°±å¾ˆå±é™©äº†ï¼ˆä¸ä¿¡ä»»ï¼‰ã€‚å¯è§£é‡Šæ€§å¯èƒ½æœ‰åŠ©äºå‘ç°æ½œåœ¨çš„é”™è¯¯ï¼ˆæ¯”å¦‚å‘ç°æ¨¡å‹é€»è¾‘å’Œ domain knowledge ä¸ç›¸ç¬¦ï¼‰ï¼Œä¹Ÿå¯èƒ½å¯ä»¥å¸®åŠ© debugï¼Œæ”¹è¿›æ¨¡å‹

- **ä¼¦ç† / æ³•è§„è¦æ±‚**
  è¯ç‰©è®¾è®¡ï¼ŒåŒ»ç–—å™¨æ¢°ï¼Œéœ€è¦ FDA æ‰¹å‡†ï¼›æ¬§ç›Ÿ GDPR (right to explanation)

- **ä½œä¸ºå…¶å®ƒç§‘å­¦ç ”ç©¶çš„å·¥å…·**
  ç§‘å­¦ç ”ç©¶æ˜¯ä¸ºäº†å‘ç°æ–°çŸ¥è¯†ã€‚å¦‚æœç¥ç»ç½‘ç»œåœ¨æŸäº›ç§‘å­¦é—®é¢˜ä¸Šæ•ˆæœå¾ˆå¥½ï¼Œé‚£è¯´æ˜å…¶å¯èƒ½å‘ç°äº†æŸç§æ–°ã€ŒçŸ¥è¯†ã€ï¼Œå¯è§£é‡Šæ€§å¯ä»¥ç”¨æ¥æ­ç¤ºå®ƒ

## How. å¯è§£é‡Šæ€§è®ºæ–‡åˆ†ç±»ç»´åº¦

ç»ˆäºåˆ°äº†æœ€é‡è¦çš„éƒ¨åˆ†â€”â€”å¯è§£é‡Šæ€§ç ”ç©¶çš„ç°çŠ¶ã€‚ä¹‹å‰çš„ç»¼è¿°æ–‡ç« çš„åˆ†ç±»å¾€å¾€ä¾èµ–äºä¸€äº› pre-recognized interpretable **explanator**sï¼ˆæ¯”å¦‚å†³ç­–æ ‘ï¼Œå†³ç­–é›†ï¼Œsaliency mapsï¼Œlinear proxy modelï¼Œfeature importance ç­‰ç­‰ï¼‰ï¼Œä½†æ˜¯å„ç§ explanator ä¹‹é—´çš„å…³ç³»å¾ˆæ··ä¹±ï¼ˆæœ‰äº›ç›¸äº’åŒ…å«ï¼Œæœ‰äº›æ ¹æœ¬ä¸åœ¨ä¸€ä¸ªå±‚é¢ä¸Šï¼‰ã€‚ä¸€ä¸ªå¥½çš„ç»¼è¿°åº”è¯¥èƒ½ä¸ºè¯¥ç ”ç©¶é¢†åŸŸæä¾›ä¸€ä¸ªã€Œåæ ‡ç³»ã€â€”â€”åŒ…æ‹¬ä¸€ç³»åˆ—æ­£äº¤çš„åˆ†ç±»ç»´åº¦ã€‚å¯¹äºå¯è§£é‡Šæ€§ç ”ç©¶ï¼Œæˆ‘ä»¬è®¤ä¸ºæœ‰ 3 ä¸ªç»´åº¦ï¼ˆè™½ç„¶è®¸å¤šå†…å®¹åœ¨ä»¥å¾€çš„è®ºæ–‡ä¸­éƒ½æœ‰æåŠï¼Œä½†æ˜¯éƒ½ä¸å®Œæ•´ï¼‰ï¼š

- **Passive (post hoc) vs. Active (intervention)**ï¼Œäº‹åè§£é‡Š vs. ä¸»åŠ¨å¹²é¢„
  â€”â€”æ˜¯å¦åœ¨æ¨¡å‹çš„æ¶æ„è®¾è®¡æˆ–è€…è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œå¹²é¢„

- **Type/Format of Explanations**ï¼Œæ‰€äº§ç”Ÿçš„è§£é‡Šçš„è¡¨ç°å½¢å¼
  åŸºæœ¬éƒ½èƒ½å½’çº³ä¸º 4 ç±»ï¼ˆè§£é‡Šå®Œæ•´ç¨‹åº¦é€’å‡ï¼‰ï¼š
  - Logic ruleï¼ŒåŒ…æ‹¬å†³ç­–æ ‘å’Œå†³ç­–é›† (decision sets) ç­‰
  - Hidden semanticsï¼Œè§£é‡Šç¥ç»ç½‘ç»œå†…éƒ¨çš„æŸä¸€éƒ¨åˆ†ï¼ˆæ¯”å¦‚å¯è§†åŒ–æŸä¸ªç¥ç»å…ƒçš„æ¿€æ´»æ¨¡å¼ï¼‰
  - Attributionï¼Œä¸çŸ¥é“æ€ä¹ˆç¿»è¯‘å¥½ï¼Œç›´è§‚çš„ä¾‹å­å°±æ˜¯ saliency maps æˆ–è€… feature importance
  - By examplesï¼Œæ¯”å¦‚ç›´æ¥è¿”å›ä¸€ä¸ªè®­ç»ƒé›†é‡Œçš„æ ·æœ¬ä½œä¸ºè§£é‡Š

- **Local-Semilocal-Global** (w.r.t. the input space)ï¼Œæ˜¯è§£é‡Šå•ç‹¬çš„è¾“å…¥è¿˜æ˜¯æ•´ä¸ªæ¨¡å‹

å›¾è§£ç‰ˆæœ¬

<figure>
  <img src="./imgs/interpretability/dim1.png" alt="" class="border">
  <figcaption>Type/Format of Explanations</figcaption>
</figure>

<figure>
  <img src="./imgs/interpretability/dim2.png" alt="" class="border">
  <figcaption>Local vs. Global</figcaption>
</figure>

### Passive (post hoc)

ç›®å‰å¤§éƒ¨åˆ†çš„å¯è§£é‡Šæ€§å·¥ä½œéƒ½é›†ä¸­åœ¨**äº‹åè§£é‡Š**ä¸Šï¼Œæ¯•ç«Ÿæœ€ç›´è§‚å¹¶ä¸”é€‚ç”¨èŒƒå›´å¹¿ã€‚ä¸‹é¢æˆ‘ä»¬å…ˆåˆ†ä¸º Passive å’Œ Active ä¸¤ä¸ªå¤§ç« èŠ‚ï¼Œç„¶åæŒ‰**æ‰€äº§ç”Ÿçš„è§£é‡Šç±»å‹**ä¾æ¬¡åˆ—ä¸¾ä¸€äº›ä»£è¡¨æ€§çš„å·¥ä½œï¼ŒåŒæ—¶åˆ†åˆ«ç”¨ **[G]**ï¼Œ**[semi-L]** å’Œ **[L]** æ¥æ ‡è¯† global/semi-local/local è§£é‡Šã€‚

#### Rules as explanations (Rule extraction)

- **KT algorithm**ï¼Œæå–å‘½é¢˜é€»è¾‘è§„åˆ™ [G]
  L. Fu, â€œRule Learning by Searching on Adapted Netsâ€, *AAAI*, 1991.
- å½¢å¦‚ **M-of-N** çš„è§„åˆ™ [G]
  G. G. Towell and J. W. Shavlik, â€œExtracting refined rules from knowledge-based neural networksâ€, *Machine Learning*, 1993.
- **Gyan**ï¼Œä¸€é˜¶é€»è¾‘è§„åˆ™ [G]
  R. Nayak, â€œGenerating rules with predicates, terms and variables from the pruned neural networksâ€, *Neural Networks*, 2009.
- æ¨¡ç³Šé€»è¾‘ [G]
  J. L. Castro et al., â€œInterpretation of artificial neural networks by means of fuzzy rulesâ€, *IEEE Transactions on Neural Networks*, 2002.
- â€¦â€¦ï¼ˆå¯ä»¥ç›´æ¥ç”¨å„ç§å†³ç­–æ ‘å­¦ä¹ ç®—æ³•ï¼Œæ¯”å¦‚ CARTã€C4.5ï¼Œæ¥æ‹Ÿåˆä¸€ä¸ªç½‘ç»œçš„è¾“å…¥è¾“å‡ºï¼‰
- **Contrastive explanations**ï¼Œé€šè¿‡æ‰°åŠ¨ä¸€ä¸ªè¾“å…¥æ¥å¯»æ‰¾å…¶å“ªäº›éƒ¨åˆ†æ˜¯å¿…ä¸å¯å°‘ / å¤šçš„ [L]
  A. Dhurandhar et al., â€œExplanations based on the missing: Towards contrastive explanations with pertinent negativesâ€, *NeurIPS*, 2018.
  2020 å¹´æœ‰ä¸€ç¯‡ NeurIPS ç»­ä½œ [G]
- **Anchors** [semi-L]
  M. T. Ribeiro et al., â€œAnchors: High-precision model-agnostic explanationsâ€, *AAAI*, 2018.
- **Interpretable partial substitute** [semi-L]
  T. Wang, â€œGaining free or low-cost interpretability with interpretable partial substituteâ€, *ICML*, 2019.

#### Explaining hidden semantics

**Hidden semantics** çš„ä¸»è¦æƒ³æ³•æ˜¯ï¼Œæ—¢ç„¶æˆ‘ä»¬è¿˜ä¸èƒ½ç†è§£æ•´ä¸ªç¥ç»ç½‘ç»œï¼Œé‚£ä¸å¦‚å…ˆå°è¯•**ç†è§£ç½‘ç»œå†…éƒ¨çš„æŸä¸€éƒ¨åˆ†**ï¼ˆæ¯”å¦‚æŸä¸ªç¥ç»å…ƒï¼ŒæŸä¸ª channelï¼‰ã€‚ç›®å‰ä¸»è¦å·¥ä½œé›†ä¸­åœ¨å¯è§†åŒ–ä¸Šï¼Œæ€è·¯å°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªèƒ½æœ€å¤§åŒ–æŸç›®æ ‡ï¼ˆæ¯”å¦‚æŸä¸ªç¥ç»å…ƒï¼‰è¾“å‡ºçš„ input pattern (activation maximization)ã€‚ä¸å¦¨å‚çœ‹ [Feature Visualization](https://distill.pub/2017/feature-visualization/)ã€‚

<figure>
  <img src="./imgs/interpretability/viz.png" alt="" class="border">
  <figcaption>C. Olah et al., â€œFeature visualizationâ€, <em>Distill</em>, 2017.</figcaption>
</figure>

å¦å¤–ä»‹ç»ä¸€ç¯‡ NLP é¢†åŸŸçš„æ–‡ç« ï¼šF. Dalvi et al., â€œWhat Is One Grain of Sand in the Desert? Analyzing Individual Neurons in Deep NLP Modelsâ€, *AAAI*, 2019.

#### Attribution

**Attribution** is to assign *credit* or *blame* to the input features in terms of their impact on the output (prediction).

<figure>
  <img src="./imgs/interpretability/attribution.png" alt="" class="border">
  <figcaption>J. Adebayo et al., â€œSanity checks for saliency mapsâ€, <em>NeurIPS</em>, 2018.</figcaption>
</figure>

- **LIME**ï¼Œ**MAPLE**ï¼Œåœ¨å±€éƒ¨æ‹Ÿåˆä¸€ä¸ªçº¿æ€§å‡½æ•° [L]
- **Partial derivatives**ï¼Œ**DeconvNet**ï¼Œ**Guided backprop**ï¼Œ**Guided Grad-CAM**ï¼ŒæŸç§æ„ä¹‰ä¸Šçš„ã€Œæ¢¯åº¦ã€[L]
- **DeepLIFT**ï¼Œ**LRP**ï¼Œ**Integrated gradients**ï¼ŒæŸç§æ„ä¹‰ä¸Šçš„ã€Œç¦»æ•£æ¢¯åº¦ã€[semi-L]
- å„ç§ **Shapley values**ï¼Œ**Sensitivity analysis**ï¼Œä¸ä¾èµ–æ¨¡å‹çš„æ–¹æ³• (model agnostic) [L]
- **TCAV**ï¼Œ**ACE**ï¼Œåœ¨æ›´é«˜å±‚é¢çš„ conceptsï¼ˆä¸å†æ˜¯ input featuresï¼‰ä¸Šåš attribution [G]
- **SpRAy**ï¼Œ**MAME**ï¼ŒæŠŠå±€éƒ¨è§£é‡Šã€Œèåˆã€æˆåŠå±€éƒ¨æˆ–å…¨å±€è§£é‡Š [semi-L, G]

#### By examples

- **Influence functions**ï¼Œå¯¹äºä¸€ä¸ªæµ‹è¯•æ ·æœ¬ï¼Œåœ¨è®­ç»ƒé›†é‡Œé¢å“ªä¸ªæ ·æœ¬å¯¹å…¶å½±å“æœ€å¤§ [L]
  P. W. Koh and P. Liang, â€œUnderstanding black-box predictions via influence functionsâ€, *ICML*, 2017.
- **Representer point selection** [L]
  C.-K. Yeh et al., â€œRepresenter point selection for explaining deep neural networksâ€, *NeurIPS*, 2018.

### Active (interpretability intervention)

ä¸»è¦çš„åšæ³•å°±æ˜¯åœ¨ç¥ç»ç½‘ç»œä¼˜åŒ–çš„è¿‡ç¨‹ä¸­åŠ å…¥ â€œinterpretability lossâ€ï¼Œçº¦æŸç½‘ç»œä½¿å…¶åœ¨æŸç§æ„ä¹‰ä¸Šæ›´å¯è§£é‡Šã€‚

#### Logic rules

- **(Regional) tree regularization**ï¼Œä½¿ç½‘ç»œæ›´å®¹æ˜“è¢«æµ…çš„å†³ç­–æ ‘æ‹Ÿåˆ [semi-L, G]
  M. Wu et al., â€œBeyond sparsity: Tree regularization of deep models for interpretabilityâ€, *AAAI*, 2018.
  M. Wu et al., â€œRegional tree regularization for interpretability in deep neural networksâ€, *AAAI*, 2020.

#### Hidden semantics

- å¸Œæœ›æ¯ä¸ªå·ç§¯æ ¸éƒ½å­¦åˆ°ç‹¬ç‰¹çš„ pattern [G]
  Q. Zhang, Y. Nian Wu, and S.-C. Zhu, â€œInterpretable convolutional neural networksâ€, *CVPR*, 2018.

#### Attribution

- **ExpO**ï¼Œå¸Œæœ› local attribution æ›´å¥½æ›´é²æ£’ [L]
  G. Plumb et al., â€œRegularizing black-box models for improved interpretabilityâ€, *NeurIPS*, 2020.
- **DAPr**ï¼Œå¸Œæœ› attribution çš„æ—¶å€™è¿˜å¯ä»¥åŒæ—¶è€ƒè™‘ä¸€äº›å…ˆéªŒ [L]
  E. Weinberger et al., â€œLearning deep attribution priors based on prior knowledgeâ€, *NeurIPS*, 2020.
- **Dual-net**ï¼Œä¸€ä¸ªç½‘ç»œé€‰æ‹©é‡è¦çš„ feature setï¼Œå¦ä¸€ä¸ªè®­ç»ƒ [G]
  M. Wojtas and K. Chen, â€œFeature importance ranking for deep learningâ€, *NeurIPS*, 2020.

#### By example

- **Prototype layer** [G]
  O. Li et al., â€œDeep learning for case-based reasoning through prototypes: A neural network that explains its predictionsâ€, *AAAI*, 2018.
  C. Chen et al., â€œThis looks like that: deep learning for interpretable image recognitionâ€, *NeurIPS*, 2019.

## æ€»ç»“

å¾—ç›Šäºå‰é¢æåˆ°çš„åˆ†ç±»ç»´åº¦ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠç°æœ‰çš„å¯è§£é‡Šæ€§è®ºæ–‡æ”¾åˆ°ä¸€ä¸ªä¸‰ç»´ç©ºé—´ä¸­ï¼ˆè®¿é—®[åœ¨çº¿ç‰ˆ](https://yzhang-gh.github.io/tmp-data/index.html)ï¼‰

<figure>
  <img src="./imgs/interpretability/paper-space.png" alt="" class="border">
</figure>

ä¸åŒç±»åˆ«çš„ç ”ç©¶æ•°é‡æœ‰å¤šæœ‰å°‘ï¼ˆæ¯”å¦‚ active ç±»çš„æ–¹æ³•æ•°é‡æ˜æ˜¾å°‘äº passive ç±»ï¼‰ï¼Œè¿™é‡Œå°±ä¸å¤šåšåˆ†æäº†ã€‚ä¸è¿‡ä»è¿‘å¹´çš„è¶‹åŠ¿æ¥çœ‹ï¼Œä¸€æ˜¯ active æ–¹æ³•çš„ç ”ç©¶å˜å¤šäº†ï¼ŒäºŒæ˜¯ local ä¸ global è§£é‡Šçš„èåˆ (multi-level) ç ”ç©¶ä¹Ÿåœ¨å¢å¤šã€‚

---

## æ‰©å±•ï¼šæ·±åº¦å­¦ä¹ ç†è®ºï¼ˆæ–¹æ³•å¯è§£é‡Šæ€§ï¼‰

è™½ç„¶æœ¬æ„åªå…³æ³¨é’ˆå¯¹å…·ä½“ç¥ç»ç½‘ç»œçš„å¯è§£é‡Šæ€§ï¼Œä½†æ˜¯åœ¨åšæ–‡çŒ®è°ƒç ”çš„è¿‡ç¨‹ä¸­ä¹Ÿçœ‹åˆ°äº†è®¸å¤šæ·±åº¦å­¦ä¹ ç†è®ºç›¸å…³çš„è®ºæ–‡ï¼Œä¸å¦‚é¡ºä¾¿ä¹Ÿåˆ†äº«ä¸€äº›ç²—æµ…çš„ç†è§£ã€‚

æ·±åº¦å­¦ä¹ æ–¹æ³•çš„å¯è§£é‡Šæ€§æœ€æ ¸å¿ƒçš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯ã€Œä¸ºä»€ä¹ˆæ·±åº¦ç¥ç»ç½‘ç»œè¿™ä¹ˆå¥½ç”¨ã€ï¼Œè¿™é‡Œçš„ã€Œå¥½ã€æŒ‡çš„æ˜¯**æ³›åŒ–æ€§èƒ½å¥½**ã€‚æŒ‰ç…§ä¼ ç»Ÿçš„è®¤è¯†ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œå‚æ•°è¿™ä¹ˆå¤šã€è¡¨è¾¾èƒ½åŠ›è¿™ä¹ˆå¼ºï¼Œé‚£åº”è¯¥å¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆè€Œå¯¼è‡´æ³›åŒ–æ€§èƒ½å·®æ‰å¯¹ã€‚å¯¹æ­¤æœ‰å¾ˆå¤šä¸åŒçš„ç ”ç©¶æ€è·¯ã€‚æ€»çš„æ¥è¯´ï¼Œå­¦ä¹ æ— éæ˜¯ä½¿ç”¨ä¸€ç§ä¼˜åŒ–ç®—æ³• $\mathcal{A}$ ä»å‡è®¾ç©ºé—´ $\mathcal{H}$ ä¸­å¯»æ‰¾å‡ºä¸€ä¸ªå‡è®¾ $h$ï¼ˆä¹Ÿå³ä¸€ä¸ªç¥ç»ç½‘ç»œï¼‰ï¼Œè¿™ä¸ªå¯»æ‰¾çš„è¿‡ç¨‹å¯ä»¥åˆ©ç”¨è®­ç»ƒé›†æ¥è¯„ä¼°ç»éªŒè¯¯å·® $\widehat{E}$ï¼Œæœ€åå¸Œæœ›èƒ½æœ€å°åŒ–åœ¨ä»æœªè§è¿‡çš„æµ‹è¯•é›†ä¸Šçš„æ³›åŒ–è¯¯å·® $E$ï¼ˆçš„æœŸæœ›å€¼ï¼‰ã€‚æ‰€ä»¥æƒ³è¦è§£é‡Šä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ æ•ˆæœå¥½â€”â€”

- **ä»å‡è®¾ç©ºé—´ $\mathcal{H}$ çš„è§’åº¦**ï¼Œæ˜¯ä¸æ˜¯å› ä¸ºæ·±åº¦ç½‘ç»œçš„æ¶æ„é€‰å¾—å¾ˆå¥½å‘¢ï¼Ÿ
  å¤§éƒ¨åˆ†çš„ç»“è®ºåŸºæœ¬éƒ½æ˜¯è¯´ï¼Œéšç€ç½‘ç»œæ·±åº¦çš„å¢åŠ ï¼Œç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›æŒ‡æ•°å¢åŠ ï¼ˆé‚£ä¹ˆé€¼è¿‘ç›¸åŒçš„å‡½æ•°æ—¶æ‰€éœ€è¦çš„å‚æ•°å°±æ¯”æµ…å±‚ç½‘ç»œå°‘ï¼Œä¸å®¹æ˜“è¿‡æ‹Ÿåˆï¼‰
  â€œThe Power of Depth for Feedforward Neural Networksâ€, *COLT*, 2016.
  â€œWhen and Why Are Deep Networks Better Than Shallow Ones?â€, *AAAI*, 2017. ç­‰ç­‰

- **ä»ä¼˜åŒ–ç®—æ³• $\mathcal{A}$ çš„è§’åº¦**ï¼Œæ˜¯ä¸æ˜¯å› ä¸ºä¼˜åŒ–ç®—æ³•å¾ˆåˆé€‚å‘¢ï¼Ÿ
  ä¸€ä¸ªå¾ˆæµè¡Œçš„è¯´æ³•æ˜¯ï¼Œsharp minima çš„æ³›åŒ–æ€§èƒ½ä¸å¥½ï¼Œè€Œ (small-batch) SGD å€¾å‘äºæ”¶æ•›åˆ° flat minimaï¼ˆæ³›åŒ–æ€§èƒ½å¥½ï¼‰ã€‚ä¸è¿‡ä¹Ÿæœ‰ä¸åŒæ„è¿™ä¸ªè¯´æ³•çš„æ–‡ç« ï¼Œè®¤ä¸ºå¯ä»¥æ„é€ ä»»æ„ sharp ä½†æ˜¯ä¹Ÿèƒ½æ³›åŒ–çš„æå°å€¼ã€‚
  â€œSharp Minima Can Generalize For Deep Netsâ€, *ICML*, 2017.

  è¿˜æœ‰å·¥ä½œå°è¯•å¯è§†åŒ–ä¸åŒæ¨¡å‹æ¶æ„ä¸‹çš„ loss surfaceï¼Œä¾¿äºç ”ç©¶æ€æ ·çš„æ¨¡å‹æ¶æ„ï¼ˆæ¯”å¦‚ç½‘ç»œæ·±åº¦ï¼Œskip connectionï¼‰ä»¥åŠä¼˜åŒ–ç®—æ³• $\mathcal{A}$ æ¯”è¾ƒå¥½ã€‚
  â€œVisualizing the Loss Landscape of Neural Netsâ€, *NeurIPS*, 2018.

- æ­¤å¤–æœ‰ä¸€äº›å¯èƒ½å¹¶ä¸æ˜¯ç”¨æ¥è§£é‡Šæ³›åŒ–æ€§èƒ½çš„ç†è®ºç ”ç©¶ï¼Œæ¯”å¦‚ SGD çš„æ”¶æ•›æ€§åˆ†æï¼Œæ­£å¥½å¯ä»¥åˆ—ä¸¾ä¸¤ä¸ªï¼ˆåœ¨ç”¨çŸ¥ä¹çš„ï¼‰å¤§ä½¬çš„è®ºæ–‡
  â€œAn Analytical Formula of Population Gradient for two-layered ReLU network and its Applications in Convergence and Critical Point Analysisâ€, *ICML*, 2017. ç”°æ¸Šæ ‹
  â€œConvergence Analysis of Two-layer Neural Networks with ReLU Activationâ€, *NeurIPS*, 2017, è¢æ´‹ï¼ˆç­‰ï¼‰

ä¸Šé¢åˆ—ä¸¾çš„è®ºæ–‡è‚¯å®šæ˜¯æŒ‚ä¸€æ¼ä¸‡ï¼Œè€Œä¸”æˆ‘è‡ªå·±ä» 2017 å¹´åº•è°ƒç ”ä¹‹åä¹Ÿæ²¡æŒç»­å…³æ³¨è¿™æ–¹é¢çš„æ–°è¿›å±•ï¼Œå†…å®¹å¯èƒ½å·²ç»è¿‡æ—¶äº†ã€‚æ›´å¤šèµ„æ–™ä¸å¦¨é¡ºç€[ç¥ç»ç½‘ç»œæœ‰ä»€ä¹ˆç†è®ºæ”¯æŒï¼Ÿ](https://zhuanlan.zhihu.com/p/27609166)å’Œ [Generalization Theory and Deep Nets, An Introduction](http://www.offconvex.org/2017/12/08/generalization1/) è¿™ä¸¤ç¯‡å¥½æ–‡å»å¯»æ‰¾ã€‚
